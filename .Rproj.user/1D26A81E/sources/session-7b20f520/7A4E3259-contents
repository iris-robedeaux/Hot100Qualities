---
title: "Hot 100 Track Exploratory Data Analysis"
author: "Iris Robedeaux"
date: "`r Sys.Date()`"
output: pdf_document
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(dplyr)
library(tidyr)
library(ggplot2)
library(pander)
library(paletteer)
library(showtext)
library(sysfonts)
library(stringr)
```

\newpage
# Introduction
|   The data I have chosen is data combined from the Billboard Hot 100 and Spotify API. It shows the songs on the Hot 100 in addition to song qualities as evaluated by Spotify's algorithm. This data was chosen for it's availability, as it's currently on Kaggle, in addition to how it combines these factors instead of being one or the other. I hope to learn more about the qualities of a Hot 100 song and trends on the charts within the past couple of decades. Something of note about the data is that many of the rows did not match with Spotify's API, so many of the rows are missing this data. They have been removed from the further analysis, so this did narrow the scope of the data. Finally, I am confident in the data scource. The songs in the data are real, and the Spotify API does have measures for what's given. 
|   The given data has 26 variables. Namely, ranking, song, band_singer, and year, which shows the ranking of a song, the name of the song, and the year it was released. There are also the lyrics, which I won't be using within this analysis, as word processing would be out of the scop of this project. There are a couple different columns used to ID the song on Genius (the lyrics source), Billboard (the chart origin), and on Spotify (the source of the song qualities). Lastly, there are qualities of the song. These song qualities are examined and given by Spotify's AI model, which evaluates songs to better it's own algorithm. 
|   The data has 3397 rows, or song instances, to begin with. This, however, does include duplicate songs that chart for multiple weeks, and there are a few rows that don't have the song qualities data. 

# Data Cleaning
```{r processing}
#import the data file
musicData <- read.csv("C:\\Users\\Iris\\Desktop\\Capstone\\Not Project 1\\billboard_24years_lyrics_spotify.csv")

#change the band/singer column to "artist"
musicData <- musicData %>% rename_at('band_singer', ~'artist')

#
musicData <- musicData %>% group_by(song, artist) %>% 
  arrange(song, ranking) %>% 
  filter(row_number() == which.min(ranking)) %>% ungroup()

#remove unnecessary columns
musicData <- musicData %>% select(-songurl, -titletext, -url, 
                                  -lyrics, -uri, -type, -id, 
                                  -track_href, -analysis_url)

#remove rows without data
musicData <- musicData %>% drop_na(mode)

#make the key a factor
musicData$key <- as.factor(musicData$key)

#turn the key numbers into the key types
musicData <- musicData %>%
                mutate(key = recode(key,   '0' = 'C', 
                                           '1' = 'C#',
                                           '2' = 'D',
                                           '3' = 'D#',
                                           '4' = 'E',
                                           '5' = 'F',
                                           '6' = 'F#',
                                           '7' = 'G',
                                           '8' = 'G#',
                                           '9' = 'A',
                                           '10' = 'A#',
                                           '11' = 'B'))


#make the mode a factor
musicData$mode <- as.factor(musicData$mode)

#turn the key numbers into the key types
musicData <- musicData %>%
                mutate(mode = recode(mode,   '0' = 'minor', 
                                             '1' = 'major'))
```
|   The data itself was quite clean, providing a great base for analysis. I did, however, make a couple tweaks to make it simpler. First, I concatenated the data so that only one instance of each song was included, just to avoid duplicates. This was done so that it was included at it's peak week, so we can see the song at it's most popular. I removed the duplicate columns for the song title, in addition to the ID columns, since they don't aid in my analysis. I also removed the lyrics because they aren't used. I then removed any rows that didn't have a "duration," thereby removing any rows without Spotify song qualities. These are necessary for my analysis, and so I won't be able to use rows without this data. I also renamed the "band_singer" column to "artist" in the interest of brevity. I converted the mode to be string values of "major" or "minor," and lastly, I edited the key column from numerical values to being the name of the musical keys. 
|   As seen in the table on the next page, the columns now indicate the peak song ranking, the song name, artist, year, if the song was a top 10 hit, and the qualities of the song, which included features like the song's key, it's duration, and several variables quantifying aspects like loudness or dancability.

\newpage
```{r}
#print the first 5 rows of the processed data
pander(head(musicData, 5), caption = "First five rows of the processed data")
```
\newpage

# Data Visualizations

## Box Plot

On the following page is box plots for the rankings of songs within each key on the Billboard Hot 100. A sort by median was considered, however the plot organized by key made more sense in this context. White dots have also been added to show the mean on each of the box plots, since it's not already a quality of this type of graph. The y-axis has been flipped to start at 100 and go upwards to 1 to emphasize that being closer to 1 is intuitively better than a ranking of 100. Some interesting aspects are that songs in B appear to be the most successful overall out of the keys. In addition, there seems to be a seasonality where the means form three positive lines, beginning at C, E, and G. It's interesting that these keys are the least charting, since they are among the most common keys used in general.

## Line Graph

On the page after the box plots, I have graphed the proportion of unique artists within each year. To prepare this data, I've calculated the number of unique artists within a year and the number of total instances of charting songs within a year. This was done because the number of songs was not even across the years, so I needed a way to give the years an even playing field so it makes more sense to compare them. I've also labelled the minimum and maximum proportions. These extrema convey that the earliest year in the data, 2000, had the most number of unique artists. The lowest is a ~0.6 in 2010, which was the year with the least number of unique artists. I've also plotted a regression line on the graph, which shows a negative trend in the amount of unique artists from year to year. This indicates that as time goes on, already prominent artists are more likely to chart than other up and coming artsts. 

\newpage

```{r}
font_add_google(name = "Roboto Serif", family = "roboto")
showtext_auto()

ggplot( musicData, aes( x = key, y = ranking, fill = key) ) +
  geom_boxplot(linewidth = 1, show.legend = FALSE) +
  stat_summary(fun = "mean", geom = "point", shape = 20,
               size = 4, color = "white")  +
  scale_y_reverse( limits = c(100,1) ) +
  scale_fill_manual( values = 
                       c("#000004FF", "#0A0722FF", "#1E0C45FF", "#380962FF", 
                         "#510E6CFF", "#69166EFF", "#801F6CFF", "#982766FF", 
                         "#B0315BFF", "#C63D4DFF", "#D94D3DFF", "#E9612BFF"))  +
  labs( x = "Song Key", y = "Billboard 100 Top Ranking", 
        title = "Top Rankings of Billboard 100 Songs by Key",
        caption = 
          str_wrap("Figure 1. Shown in key order, box plots are given for the peak position of songs on the Billboard Hot 100 chart. White points are given to show the mean value for each key. The y-axis begins at 100 and goes up to 0 to more intuitively show how a ranking of 1 is optimal.",
                   width = 75)) +
  theme_classic() +
  theme(legend.position="none", 
        axis.text.x = element_text(family = "roboto", size = 9, face = "bold"),
        axis.text.y = element_text(family = "roboto", size = 9, face = "bold"),
        axis.title = element_text(family = "roboto", size = 12, face = "bold"),
        plot.title = element_text(family = "roboto", size = 16, face = "bold", hjust = 0.5),
        plot.caption = element_text(family = "roboto", size = 10, face = "bold", hjust = 0),
        axis.line = element_line(linewidth = 1),
        axis.ticks.length = unit(.25, "cm"),
        axis.ticks = element_line(linewidth = 1)) 
```

\newpage

```{r}
#get unedited data
musicDataNew <- read.csv("C:\\Users\\Iris\\Desktop\\Capstone\\Not Project 1\\billboard_24years_lyrics_spotify.csv")

musicDataNew <- musicDataNew %>% select(band_singer, year)

# Get the unique artists and total instances for each year
artistUnq <- musicDataNew %>%
                    group_by(year) %>%
                            summarize(
                              uniqArtists = n_distinct(band_singer),
                              totalInstances = n())

artistUnq$prop <- artistUnq$uniqArtists / artistUnq$totalInstances
```

```{r}
font_add_google(name = "Roboto Serif", family = "roboto")
showtext_auto()

#get min and max points
min_point <- artistUnq[which.min(artistUnq$prop), ]
max_point <- artistUnq[which.max(artistUnq$prop), ]

ggplot( artistUnq, aes(x = year, y = prop) ) +
  geom_line(color = "darkorange3", linewidth = 1.5 ) +
  geom_point( color = "darkorange3", size = 3 ) +
  geom_smooth(method='lm', 
              formula= y ~ x, 
              color = "darkblue",
              linewidth = 1.25,
              alpha = 0.325 ) +
  labs( x = "Year", 
        y = "Proportion of Unique Artists",
        title = "Proportion of Unique Artists on Billboard Hot 100 by Year",
        caption = str_wrap("Figure 2. There is a year by year proportion of unique artists to total amount of songs for a year on the Billboard Hot 100 within the data. A regression line is shown on the graph in blue with a transparent confidence interval band around it.", 
                           width = 75)) +
  annotate("text", 
           x = min_point$year, 
           y = min_point$prop, 
           label = paste("Min:", round(min_point$prop, 3)), 
           vjust = 2, 
           color = "blue", 
           size = 4,
           family = "roboto") +
  annotate("text", 
           x = max_point$year, 
           y = max_point$prop, 
           label = paste("Max:", round(max_point$prop, 3)), 
           vjust = -1, 
           hjust = .25,
           color = "red", 
           size = 4,
           family = "roboto") +
  scale_y_continuous(limits = c(0.5, 1)) +
  scale_x_continuous(breaks = seq(2000, 2025, by = 2)) +
  theme_bw() +
  theme(legend.position="none", 
        axis.text.x = element_text(family = "roboto", size = 9, face = "bold"),
        axis.text.y = element_text(family = "roboto", size = 9, face = "bold"),
        axis.title = element_text(family = "roboto", size = 12, face = "bold"),
        plot.title = element_text(family = "roboto", size = 14, face = "bold", hjust = 0.5),
        plot.caption = element_text(family = "roboto", size = 10, face = "bold", hjust = 0),
        axis.line = element_line(linewidth = 1),
        axis.ticks.length = unit(.25, "cm"),
        axis.ticks = element_line(linewidth = 1)) 
```

# Conclusions

```{r}
summary(aov(ranking ~ key, data = musicData))
```


After completing these charts, I was interested in the relationship between a song's Key and it's Ranking. I completed a one-way ANOVA test to identify a relationship, which provided a p-value of 0.027, indicating that under a $\alpha = 0.05$ test, Key is an important predictor for a song's ranking. To test the assumptions of an ANOVA, I peeked at the Residuals vs Fitted plot in addition to the Q-Q plot. Both of these plots looked as they should, indicating that normality and equal variance assumptions were met. Given more time, I would look further into this relationship. I would also look more into the number of artists decreasing over time, which would provide an analysis that shows trends in music over time. This is opposed to my previous analysis of the data, where I explored the qualities of a Top 10 song. The difficulty with this data set is that it contains charting songs, which means that every song in the data set has been popular, which makes it difficult to analyze when there is no control group of unpopular songs. All in all, I learned about the relationships between variables in the data, which gives me more insight into Hot 100 data. 

# GitHub Repository
